## 읽은 논문에 대해서 매일 준비한 세미나 발표자료
### contribution 위주로 정리
---
# 정리 페이지 Notion으로 이전 (leesuhyeong.notion.site/study)
------
## Done
| Name                                                                                                                                              | Keyword                     | Publish    | arxiv  | ...           |
|---------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------|------------|--------|---------------|
| [GLIDE](./Generative/GLIDE/GLIED.md)                                                                                                              | Inpainting                  | ICML 2021  | 21.12  |               |
| [DALLE2](./Generative/DALLE2/DALLE2.md)                                                                                                           | Text2Image                  |            | 22.04  |               |
| [DALLE3](./Generative/DALLE3/DALLE3.md)                                                                                                           | Text2Image                  |            | 23.09? |               |
| [Blended Diffusion](./Generative/Blended_Diffusion/Blended_Diffusion.md)                                                                          | Inpainting                  | CVPR 2022  | 21.11  |               |
| [Bledned_Latent_Diffusion](./Generative/Bledned_Latent_Diffusion/Bledned_Latent_Diffusion.md)                                                     | Inpainting                  | ACM 2022   | 22.06  |               |
| [text2live](./Generative/text2live/text2live.md)                                                                                                  | Image Blending              | ECCV 2022  | 22.04  |               |
| [zoom-to-inpaint](./Generative/zoom-to-inpaint/zoom-to-inpatint.md)                                                                               | Inpainting                  | CVPRW 2022 | 20.12  |               |
| [Differential Diffusion: Giving Each Pixel Its Strength](./Generative/Differential_Diffusion/Differential_Diffusion.md)                           | Inpainting                  |            | 23.06  |               |
| [All are Worth Words: A ViT Backbone for Diffusion Models](./Generative/All_are_Worth_Words/All_are_Worth_Words.md)                               | Diffusion                   | CVPR 2022  | 22.09  |               |
| [Foreground-Background Separation through Concept Distillation from](./Generative/Foreground-Background_Separation/main.md)                       | Segmentation                | ICCV 2023  | 22.12  |               |
| [MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models](./Generative/MagicFusion/main.md)                         | Diffusion Ensemble          | ICCV 2023  | 23.03  |               |
| [Unleashing Text-to-Image Diffusion Models for Visual Perception](./Generative/Visual_Perception_Diffusion/main.md)                               | Segmentation                | ICCV 2023  | 23.03  |               |
| [Null-text Inversion for Editing Real Images using Guided Diffusion Models](./Generative/Null-text_Inversion/main.md)                             | Inversion                   | CVPR 2023  | 22.11  |               |
| [DASO: Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning](./Generative/Semi-Supervised/DASO/main.md)     | SSL, CLS                    | CVPR 2022  | 21.06  |               |
| [DiffusinoCLIP: Text-Guided Diffusion Models for Robust Image Manipulation](./Generative/DiffusionCLIP/main.md)                                   | Inversion                   | CVPR 2022  | 21.10  |               |
| [Prompt Tuning Inversion for Text-Driven Image Editing Using Diffusion Models](./Generative/Prompt_Tuning_Inversion/main.md)                      | Inversion                   | ICCV 2023  | 23.05  |               |
| [Editing Implicit Assumptions in Text-to-Image Diffusion Models](./Generative/Editing_Implicit_Assumptions/main.md)                               | Model Editing               | ICCV 2023  | 23.03  |               |
| [MAG-Edit: Localized Image Editing in Complex Scenarios via Mask-Based Attention-Adjusted Guidance](./Generative/MAG-Edit/main.md)                | Inpainting                  |            | 23.12  |               |
| [DreamInpainter: Text-Guided Subject-Driven Image Inpainting with Diffusion Models](./Generative/DreamInpainter/main.md)                          | Inpainting, Personalized    |            | 23.12  |               |
| [Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models](./Generative/Attend-and-Excite/main.md)                 | Text align                  | ACM 2023   | 23.01  |               |
| [DALL-E for Detection: Language-driven Compositional Image Synthesis for Object Detection](./Generative/DALL-E_for_Detection/main.md)             | Synthetic data for OD       |            | 22.06  |               |
| [Dreambooth](./Generative/DreamBooth/main.md)                                                                                                     | Personalized                | CVPR 2022  | 22.08  |               |
| [DiffusionClassifier](./Generative/DiffusionClassifier/main.md)                                                                                   | Classification              | ICCV 2023  | 23.03  |               |
| [X-Paste: Revisiting Scalable Copy-Paste for Instance Segmentation using CLIP and StableDiffusion](./Generative/X-Paste/main.md)                  | Synthetic data for SG       | ICML 2022  | 22.12  |               |
| [DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection](./Generative/DiffusionEngine/main.md)                             | Synthetic data for OD       |            | 23.09  |               | 
| [PHOTOSWAP: Personalized Subject Swapping in Images](./Generative/PhotoSwap/main.md)                                                              | Personalized                | NIPS 2023  | 23.05  | 내용 부실함        |
| [Adding Conditional Control to Text-to-Image Diffusion Models](./Generative/ControlNet/main.md)                                                   | Fintuning Diffusion         | ICCV 2023  | 23.02  | 내용 부실함        |
| [Estimation of Non-Normalized Statistical Models by Score Matching](./Generative/ScoreMatching/main.md)                                           | Score-based                 | MLR 2005   |        |               |
| [Shape-Guided Diffuion with Inside-Outside Attention](./Generative/Shape-Guided_Diffusion/main.md)                                                | Inpainting                  |            | 22.12  |               |
| [Compositional Visual Generation with Composable Diffusion Models](./Generative/ComposableDiffusion/main.md)                                      | Compose condition           | ECCV 2022  | 22.06  |               |
| [SmartMask: Context Aware High-Fidelity Mask Generation for Fine-grained Object Insertion and Layout Control](./Generative/SmartMask/main.md)     | Inpainting                  |            | 23.12  |               |
| [Guided Image Synthesis via Initial Image Editing in Diffusion Model](./Generative/Guided_Initial_Image_Editing/main.md)                          | Image Editing               | ACMMM 2023 | 23.05  | Initial Noise |
| [Pretraining is All You Need for Image-to-Image Translation](./Generative/Pretraining_for_I2I_Translation/main.md)                                | I2I translation             |            | 22.05  |               |
| [InstructPix2Pix: Learning to Follow Image Editing Instructions](./Generative/InstructPix2Pix/main.md)                                            | I2I translation             | CVPR 2022  | 22.11  |               |
| [Estimation of Non-Normalized Statistical Models by Score Matching](./Generative/ScoreMaching/main.md)                                            | scroe matching              | MLR 2005   |        |
| [Sliced Score Matching: A Scalable Approach to Density and Score Estimation](./Generative/SlicedScoreMatching/main.md)                            | score matching              | UAI 2019   | 19.05  |               |
| [Negative-prompt Inversion: Fast Image Inversion for Editing with Text-guided Diffusion Models](./Generative/Negative-Prompt_Inversion/main.md)   | Inversion                   |            | 23.05  |               |
| [InstructDiffusion: A Generalist Modeling Interface for Vision Tasks](./Generatvie/InstructDiffusion/main.md)                                     | Instruct based AGI          |            | 23.09  |               |
| [PNP INVERSION: BOOSTING DIFFUSION-BASED EDITING WITH 3 LINES OF CODE](./Generative/PnP_Inversion/main.md)                                        | Inversion                   | ICLR 2024  | 23.10  |               |
| [SDXL: Improving latent Diffusion models for high_resolution image synthesis](./Generative/SDXL/main.md)                                          | Stable Diffusion            | ICLR 2024  | 23.07  |               | 
| [Interpolating between Images with Diffusion Models](./Generative/Interpolating_with_Diffusion/main.md)                                           | Interpolation               |            | 23.07  |               |
| [PIXART-α: FAST TRAINING OF DIFFUSION TRANSFORMER FOR PHOTOREALISTIC TEXT-TO-IMAGE SYNTHESIS](./Generative/PixArt-a/main.md)                      | Efficient                   | ICLR 2024  | 23.10  |               |
| [IMAGENHUB: STANDARDIZING THE EVALUATION OF CONDITIONAL IMAGE GENERATION MODELS](.Generative/ImagenHub/main.md)                                   | Benchmark                   | ICLR 2024  | 23.10  |               |
| [Self-Attention with Relative Position Representations](./Generative/Relative_position_embedding/main.md)                                         | Transformer                 | NAACL 2018 | 18.03  |               |  
| [Video Diffusion Models](./Generative/VideoDiffusion/main.md)                                                                                     | Video Generation            | NIPS 2022  | 22.04  |               |
| [AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning](./Generative/AnimateDiff/main.md)                 | Video Generation            | ICLR 2024  | 23.07  |               |
| [Inversion based_StyleTransfer](./Generative/Inversion-based_StyleTransfer/main.md)                                                               | Style Transfer              | CVPR 2022  | 22.11  |               |
| [Rein: Harnessing Visionss Foundation Models](./DomainGeneralization/Rein/main.md)                                                                | DGSS                        | CVPR 2024  | 23.12  |               |
| [StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models](./Generative/StyleDiffusion/main.md)                              | Style Transfer              | ICCV 2023  | 23.08  |               |
| [De-Diffusion Makes Text a Strong Cross-Modal Interface](./Generative/De-Diffusion/main.md)                                                       | Image Captioning            | CVPR 2024  | 23.11  |               |
| [Matryoshka diffusion Models](./Generative/Matryoshka_Diffusion_Models/main.md)                                                                   | High-resolution             | ICLR 2024  | 23.10  |               |
| [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](./LargeLangeageModels/Chain-of-Thought/main.md)                           | LLM Prompting               | NIPS 2022  | 22.01  |               |
| [Compositional Text-to-Image Synthesis with Attention Map Control of Diffusion  Models](./Generative/BoxNet/main.md)                              | attetnion control           |            | 23.05  |               |
| [Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video](./Self-Supervised/DoRA/main.md)                          | self-supervised using video | ICLR 2024  | 23.10  |               |
| [Erasing Concepts from Diffusion Models](./Generative/Erased_StableDiffusion/main.md)                                                             | undesirable image removal   | ICCV 2023  | 23.03  |               |
| [Is Synthetic Data form Generative Models Ready for Image Recognition?](./Generative/SyntheticData_Ready_for_ImageRcognition?/main.md)            | Sythetic data               | ICLR 2023  | 22.10  |               |
| [DatasetDM: Synthesizing Data with Perception Annotations Using Diffusion Models](./Generative/DatasetDM/main.md)                                 | Sythetic data               | NIPS 2023  | 23.08  |               |
| [GeoDiffusion: text-prompted Geometric control for Object Detection Data Generation](./Generative/GeoDiffusion/main.md)                           | Sythetic data               | ICLR 2024  | 23.06  |               |
| HyperNetworks                                                                                                                                     |                             |            |        |               |
| [Prompt-to-Prompt Image Editing with Cross-Attention Control](./Generative/Prompt-to-Prompt/main.md)                                              | Text-to-Image Editing       | ICLR 2022  | 22.08  |               |
| [Learning Transferable Visual Models From Natural Language Supervision](./VLM/CLIP/main.md)                                                       | VLM                         | ICML 2021  | 21.03  |               |
| [Visual Instruction Tuning](./VLM/LLAVA/main.md)                                                                                                  | VLM                         | NIPS 2023  | 23.04  |               |
| [LayoutTransformer: Layout Generation and Completion with Self-attention](./Document/LayoutTransformer/main.md)                                   | Layout Generation           | ICCV 2020  | 20.06  |               |
| [BLT: Bidirectional Layout Transformer for Controllable Layout Generation](./Document/BLT/main.md)                                                | Layout Generation           | ECCV 2021  | 21.12  |               |
| [Unifying Vision, Text, and Layout for Universal Document Processing](./Document/UDOP/main.md)                                                    | Layout Foundation Model     | CVPR 2023  | 22.12  |               |
| EDICT                                                                                                                                             |                             |            |        |               |
| Fader Networks                                                                                                                                    |                             |            |        |               |
| MasaCtrl                                                                                                                                          |                             |            |        |               |
| On Distillation of Guided Diffusion Models                                                                                                        |                             |            |        |               |
| Classifier-Free Diffusoin Guidance                                                                                                                |                             |            |        |               |
| [GLIP : Grounded Language Image Pretraining](./VLM/GLIP/main.md)                                                                                  | multi modal OD              | CVPR 2021  | 21.12  |               |
| Generate Anything Anywhere in Any Scene                                                                                                           |                             |            |        |               |
| Semantic Object Accuracy for Generative Text-to-Image Synthesis                                                                                   |                             |            |        |               |
| [GLIGEN: Open-Set Grounded Text-to-Image Generation](./Generative/GLIGEN/main.md)                                                                 | Generative                  | CVPR 2023  | 23.01  |               |
| [JourneyDB](./Generative/JourneyDB/main.md)                                                                                                       |                             |            |        |               |
| [Drag Your GAN](./Generative/DragGAN/main.md)                                                                                                     |                             |            |        |               |
| [DragDiffusion](./Genrative/DragDiffusion/main.md)                                                                                                |                             |            |        |               |
| [DragonDiffusion](./Genrative/DragonDiffusion/main.md)                                                                                            |                             |            |        |               |
| [CLIP know about a red circle?](./VLM/CLIP_RedCircle/main.md)                                                                                     |                             |            |        |               |
| [ReVersion](./Genrative/Reversion/main.md)                                                                                                        |                             |            |        |               |
| [BERT score](./LLM/BertScore/main.md)                                                                                                             |                             |            |        |               |
| [Evaluating and Improving Factuality in Multimodal Abstractive Summarization](./VLM/CLIPBERTscore/main.md)                                        |                             |            |        |               |
| [High-Resolution Image Synthesis with Latent Diffusion Models](./Generative/LDM/main.md)                                                          |                             |            |        |               |
| [StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners](./Generative/StableRep)                        |                             |            |        |               |
| ImageBrush                                                                                                                                        |                             |            |        |               |
| [GLIPv2: Unifying Localization and Vision-Language Understanding](./VLM/GLIPv2/main.md)                                                           | multi modal OD              | NIPS 2022  | 22.06  |               |
| Generative Modeling by Estimating Gradients of the Data Distribution                                                                              |                             |            |        |               |
| LoRA                                                                                                                                              |                             |            |        |               |
| [IMAGEN:Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](./Generative/IMAGEN/main.md)                              | text-to-image               | NIPS 2022  | 22.05  |               |
| An Edit Friendly DDPM Noise Space: Inversion and Manipulations                                                                                    |                             |            |        |               |
| Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance                                                         |                             |            |        |               |
| AnyDoor                                                                                                                                           |                             |            |        |               |
| LEDITS                                                                                                                                            |                             |            |        |               |
| SEGA                                                                                                                                              |                             |            |        |               |
| Collage Diffusion                                                                                                                                 |                             |            |        |               |
| DiffEdit                                                                                                                                          |                             |            |        |               |
| Paint by Word                                                                                                                                     |                             |            |        |               |
| Improving Sample Quality of Diffusion Models Using Self-Attention Guidance                                                                        |                             |            |        |               |
| DALLE-2 is Seeing Double: Flaws in Word-to-Concept Mapping in Text2Image Models                                                                   |                             |            |        |               |
| CoCa                                                                                                                                              |                             |            |        |               |
| T2I-CompBench                                                                                                                                     |                             |            |        |               |
| Clipscore                                                                                                                                         |                             |            |        |               |
| SmartBrush                                                                                                                                        |                             |            |        |               |
| ILVR                                                                                                                                              |                             |            |        |               |
| [BK-SDM: Architecturally Compressed Stable Diffusion for Efficient Text-to-Image Generation](./Generative/LightweightingDiffusion/BK-SDM/main.md) | Lightweighting Diffusion    | ICML 2023  | 23.05  |               |
| [EdgeFusion: On-Device Text-to-Image Generation](./Generative/LightweightingDiffusion/EdgeFusion/main.md)                                         | Lightweighting Diffusion    |            | 24.04  |               |
| [Paint by Inpaint: Learning to Add Image Objects by Remobing Them First](./Generative/Paint_by_Inpaint/main.md)                                   | instruct based editing      |            | 24.04  |               |
| [StoryDiffusion: Consistent Self-attention for Long-range Image and Video Generation](./Generative/StoryDiffusion/main.md)                        | consistent generation       |            | 24.05  |               |
| [Customizing Text-to-Image Models with a Single Image Pair](./Generative/PairCustomization/main.md)                                               | Style transfer              |            | 24.05  |               |
| [Visual Fact checker: Enabling High-Fidelity Detailed Caption Generation](./Generative/Visual_Fact_Checker/main.md)                               | Captioning                  |            | 24.04  |               |
| [An Image is Worth 32 Tokens for Reconstruction and Generation](./Generative/TiTok/main.md)                                                       | Vector Quantizing           |            | 24.06  |               |
| [MimicBrush: Zero-shot Image Editing with Reference Imitation](./Generative/MimicBrush/main.md)                                                   | Image Editing               |            | 24.06  |               |
| [You Only Look Once: Unified, Real-Time Object Detection](./ObjectDetection/YOLOv1/main.md)                                                       | Object Detection            | CVPR 2015  | 15.06  |               |
| [YOLO9000:Better, Faster, Stronger](./ObjectDetection/YOLOv2/main.md)                                                                             | Object Detection            | CVPR 2016  | 16.12  |               |
| [YOLOv3: An Incremental Improvement](./ObjectDetection/YOLOv3/main.md)                                                                            | Object Detection            |            | 18.04  |               |
| [Magic Fixup: Streamlining Photo Editing by Watching Dynamic Videos](./Generative/MagicFixup/main.md)                                             | Image editing               |            | 24.03  |               |
| [Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model](./Generative/Transfusion/main.md)                             | Cross-modal Generation      |            | 24.08  |               |
| [Can OOD Object Detectors Learn from Fundation Models?](./Generative/SyncOOD/main.md)                                                             | OOD                         |            | 24.09  |               |
| [TextBoost: Towards One-Shot Personalization of Text-to-Image Models via Fine-tuning Text Encoder](./Generative/TextBoost/main.md)                | Personalization             |            | 24.09  |               |
| [Imagine yourself: Tuning-Free Personalized Image Generation](./Generative/ImagineYourself/main.md)                                               | Personalization             |            | 24.09  |               |
| [ADD-IT: Training-Free Object Insertion in Images with Pretrained Diffusion Models](./Generative/ADD-IT/main.md)                                  | Image Insertion             |            | 24.11  | NVIDIA        |
| [DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception](./Generative/DetDiffusion/main.md)                                  | Data Generation for OD             |CVPR 2024            | 24.03    |         |
| [EraseDraw: Learning to Inser Objects by Erasing Them from Images](./Generative/EraseDraw/main.md) | Instruct                              | ECCV 2024           |  24.09      |               |
| [Low-Rank Few-Shot Adaptation of Vision-Language Models](./VLM/CLIP-LoRA/main.md)    | CVPR 2024                            |  24.05          |        |               |
| [BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion](./Generative/BrushNet/main.md)    | Inpainting                            |  ECCV 2024          | 24.03       |               |
| [Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator](./Generative/Diptych_Prompting/main.md)    |   Subject driven Inpainting    |            |  24.11      |               |
| [GlyphDraw: Seamlessly Rendering Text with Intricate Spatial Structures in Text-to-Image Generation](./Generative/GlyphDraw/main.md)    | Visual Text Generation                             |            |  23.03      |               |
| [One-Step Image Translation with Text-to-Image Models](./Generative/Img2ImgeTurbo/main.md)    | Unsupervied Image2Image translation                        |            |    24.03    |               |
| [Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All](./Generative/Diffuse_to_Choose/main.md)    |  subject guided inpainting                           |            |   24.01     |   Amazon            |
| [CycleNet: Rethinking Cycle Consistency in Text-guided Diffusion for Image Manipulation](./Generative/CycleNet/main.md)               | unpaired img2img translation  |  NIPS 2023   |  23.10      |               |



----------------------------------------------------------------
| [abc](.///main.md)               | task  |  aaaa 2023   |  20.00    |               |